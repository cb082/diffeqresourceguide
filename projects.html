<html>

<head>
	<title>T. Schmid</title>
	
	<meta charset="UTF-8">
	<meta name="description" content="Todd Schmid's personal webspace.">
	<meta name="keywords" content="mathematics,post-graduate,logic,todd,schmid,pplv,london">
	<meta name="author" content="Todd Schmid">
	
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<link rel="stylesheet" type="text/css" href="http://tikzjax.com/v1/fonts.css">
	<script src="http://tikzjax.com/v1/tikzjax.js"></script>

	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	
	<link rel="stylesheet" href="styles.css" />
	<link rel="icon" href="squidab.png" />
</head>

<body>
	<div id="content">
		<div id="head">
			<div id="links">
				<a href="index.html"><span class="link">Personal</span></a>
				<a href="math.html"><span class="link">Math</span></a>
				<a href="cv.html"><span class="link">CV</span></a>
				<!--<a href="movienight.html"><span class="link">Movie Nights</span></a>-->
				<a href="teaching.html"><span class="link">Teaching</span></a>
			</div>
		</div>

		<div id="stuff">
			<a class="link" id="tab" href="math.html"><h1>Interests/Past Work</h1></a>
			
			<h1>Projects</h1>
			<h4>Contents</h4>
			<list>
				<li><a href="#one">Characterizing Automata with Coequations</a></li>
				<li><a href="#two">Writing Proofs Stochastically</a></li>
				<li><a href="#three">A Graphical Representation of Formulas</a></li>
			</list>

			<h3 id="one">I. Regular Expressions via Coequations</h3>
			<p>
				[Under construction...]
			</p>

			<h4>References</h4>
			<ol>
				<li>Baeten, Jos CM, Flavio Corradini, and Clemens A. Grabmayer. "A characterization of regular expressions under bisimulation." Journal of the ACM (JACM) 54.2 (2007): 6-es.</li>
				<li>Rutten, Jan JMM. "Universal coalgebra: a theory of systems." Theoretical computer science 249.1 (2000): 3-80.</li>
				<li>AMEK, JIRÍAD, and HANS–E. PORST. "On Varieties and Covarieties in a Category."</li>
			</ol>

			<h3 id="two">II. Writing Proofs Stochastically</h3>
			<p>
				Often, the first time you try to write a proof, you make some guesses that lead you down a blind alley. How nice would it be to be able to compute the probability that the path you’re taking goes nowehere? I'm not about to claim that this probability is always computable ahead of time. However, I think it's likely computable ad hoc, and in certain circumstances. 
			</p>

			<p>
				Suppose we were to construct a machine that, given a sequence of rules and a sequent in some logic, stochastically constructs a derivation tree. My main questions in this direction are...
				<ol type="a"> 
					<li>In which circumstances is the likelihood of a specific derivation having taken place computable?</li>
					<li>Can we have such a machine learn from its failures? That is, if we adjust the probability distribution for the constructon at each derivation step, can we make proofs more likely to appear?</li>
				</ol>
				These questions are, of course, somewhat vague at the moment. But here is a setup in which they make sense: Let's define a <i>logic</i> \(\mathcal L\) to be a set of <i>sequents</i> \(S_{\mathcal L}\) and a set of <i>derivation rules</i> \(R_{\mathcal L}\). A member \(r \in R_{\mathcal L}\) is an \((n_r+1)\)-ary relation on \(S_{\mathcal L}\), and I will write
				\begin{align*}
					s_1 && \dots && s_{n_r}\\
					\hline
					&& s && (r)
				\end{align*}
				to mean\[
					(s_1, \dots, s_{n_r}, s) \in r,
				\]
				and say that \((s_1, \dots, s_{n_r}, s)\) is an <i>instance of rule</i> \((r)\), as is usually done in proof theory. If \(n_r = 0\), then \((r)\) is said to be an <i>axiom</i>. The set \(\mathcal D_{\mathcal L}\) of <i>(abstract) derivation trees</i> of \(\mathcal L\) is constructed recursively as follows: For any sequent \(s\), the upwards-directed graph with a single node \(v^{(s)}\), labelled by \(s\), is an abstract derivation tree. Next, given any abstract derivation tree \(t\) and any of its leaf vertices \(v^{(s)}\), if \((s_1, \dots, s_r, s)\) is an instance of rule \((r)\),
				the tree \(t'\), obtained by replacing \(v^{(s)}\) with the labelled tree 
				<div class="medium_image"><img src="images/derivation_step.png" /></div>
				is an abstract derivation tree. To denote that \(t'\) is obtained from \(t\) by applying the proof rule \((r)\) to one of its leaves, I will use \(t \xrightarrow{r} t'\), preempting the link to automata theory in next paragraph. An abstract derivation tree whose leaves are all labelled with axioms is called a <i>proof</i>.
			</p>

			<p>
				There are, potentially, many different abstract derivation trees \(t'\) for which \(t \xrightarrow{r} t'\). For now, I will assume that these will be only finite in number, to avoid having to involve analysis later on. Anyway, the <i>abstract derivation machine</i> for \(\mathcal L\) is the function
				\[
					\delta_{\mathcal L}: D_{\mathcal L} \longrightarrow 2 \times \mathcal P(D_{\mathcal L})^{R_{\mathcal L}}
				\]
				that takes a tree \(t\) to the pair \((b, \delta_rt)\), where
				\begin{align*}
					b = 1 && \text{iff} && \text{every leaf of \(t\) is labelled with an axiom}
				\end{align*}
				and\[
					\delta_rt = \{t' \mid t \xrightarrow{r} t'\}.
				\]
				The function \(\delta_{\mathcal L}\) is an example of a <a href="https://ncatlab.org/nlab/show/nondeterministic+automaton" target="_blank">nondeterministic automaton</a>.
			</p>

			<p>
				Anyone familliar with the process will know that the jump from nondeterministic automata to probabilistic automata (see [1]) is not a large one: Instead of assigning a set of possible derivation steps to every tree and rule, we simply need to give a probability distribution to the possible derivation steps instead. This would yield a function of the form
				\[
					\delta_{\mathcal L}^\eta: D_{\mathcal L} \longrightarrow 2 \times \mathbb D_f(D_{\mathcal L})^{R_{\mathcal L}},
				\]
				(parameterized by a variable \(\eta\) that I will mention in a second) where \(\mathbb D_f(X)\) is the set of probability distributions on \(X\) with finite support. It remains to decide how \(\delta_{\mathcal L}\) should distribute probabilities. So far, all I have looked at is the uniform distribution: For any abstract derivation tree \(t\) and rule \(r\),
				\[
					\delta_r^{\text{Unif}}t(t') = \left\{\begin{array}{ll}
						\frac{1}{|\delta_rt|} & \text{ if $t' \in \delta_rt$}\\
						0 & \text{ otherwise}
					\end{array}\right..
				\]
				Yes, \(\delta_r^{\text{Unif}}\) essentially writes proofs randomly. The purpose of \(\eta\) is probably clear at this point: \(\eta\) indexes the multitude of choices in distribution. I would like to know what happens when we make other well-defined choices in distribution, of course, and whether or not we can train a machine of this sort by varying \(\eta\) to optimise the likelihood of writing proofs.
			</p>

			<p>
				This project is more or less for-fun, so I'm going to stop here and hope that somebody reading this might be interested in contributing. As a starting point, I have some questions about the first machine \(\delta_{\mathcal L}\) I'd particularly like to see worked out: 
				<ol type="i">
					<li>Pick your favourite propositional <a href="https://en.wikipedia.org/wiki/Substructural_logic" target="_blank">substructural logic</a>. What, syntactically, do <a href="https://en.wikipedia.org/wiki/Bisimulation" target="_blank">bisimilar</a> sequents have in common? Are there interesting logics for which bisimilarity is not simply given by sequences of proposition substitutions?</li>
					<li>Extending i, what happens when we minimize (in the sense of [2])? What could this have to do with proof theory?</li>
					<li>How is this approach similar to the ones taken in [3] and [4]?</li>
				</ol>
				Maybe these questions don't have interesting answers, but...maybe they do! In the words of Lenny Turteltaub, "What do [abstract derivation machines] know [about automated theorem proving]? Do they know things? Let's find out!"
			</p>

			<h4>References</h4>
			<ol>
				<li>Rabin, Michael O. "Probabilistic automata." Information and control 6.3 (1963): 230-245.</li>
				<li>Bonchi, Filippo, et al. "Algebra-coalgebra duality in brzozowski's minimization algorithm." ACM Transactions on Computational Logic (TOCL) 15.1 (2014): 1-29.</li>
				<li>Schubert, Aleksy, Wil Dekkers, and Henk Barendregt. "Automata theoretic account of proof search." (2015).</li>
				<li>Zielenkiewicz, Maciej, and Aleksy Schubert. "Automata theory approach to predicate intuitionistic logic." International Symposium on Logic-Based Program Synthesis and Transformation. Springer, Cham, 2016.</li>
			</ol>

			<h3 id="three">III. A Graphical Representation of Formulas</h3>
			<p>
				This project is all about representing logical formulas with graphs, and characterizing the formula-representing graphs by structural constraints. The current focus is on the formulas of any logic built out of some number of parallel monoidal closed structures, especially <a href="https://en.wikipedia.org/wiki/Bunched_logic" target="_blank">bunched implication logic</a>. At the moment, a faithful graph-theoretic representation of the multiplicative fragment of propositional bunched implication logic <a href="https://drive.google.com/file/d/1gzJ6Jwmryi0url60grpA3E993U1jqqeH/view?usp=sharing" target="_blank">exists</a>, and the graphs it produces are characterized. The general case is still under construction, but looks promising.
			</p>

			<p>
				It was first noticed in the 70s that a faithful representation of propositions in classical propostional logic could be represented with simple graphs whose vertices were labelled by propositions. This was later used in [1] to give a combinatorial account of classical propositional logic's proof theory, which was extended in [2] to full classical predicate logic and in [3] to several modal logics.
			</p>

			<p>
				To give a flavour of the work involved, what follows is a brief account of the representation of classical propositional formulas that appears in [1]. Given a formula \(\varphi\) grammatically constructed from the rules
				\[
					A,B ::= p \in \mathbf{Prop} \mid \bar p \mid A \wedge B \mid A \vee B,
				\]
				the simple graph \([\![\varphi]\!]\) associated with \(\varphi\) is defined recursively as follows: For any literal \(a\),
				\[
					[\![a]\!] = (\{v^{(a)}\}, \emptyset)
				\]
				is the graph with a single vertex labelled "\(a\)". For any formulas \(A,B\),
				\[
					[\![A \vee B]\!] = [\![A]\!] \sqcup [\![B]\!]
				\] 
				is given by disjoint union, and 
				\[
					[\![A \wedge B]\!] = [\![A]\!] |\!| [\![B]\!] := [\![A]\!] \sqcup [\![B]\!] + \{v \frown w \mid v \in [\![A]\!], w \in [\![B]\!]\}
				\]
				is given by a disjoint union followed by fully connecting vertices between the two components (notice that \(|\!|\) and \(\sqcup\) are associative and commutative operations!). For example, \([\![q \wedge (\bar q \vee p)\wedge r]\!]\) is the following graph.
			</p>
			<p>
				<div class="small_image">
					<img src="images/cograph_example.png" />
				</div>
				Any graph constructed from a formula in this manner is called a <i>cograph</i>. This representation of classical propositional formulas is <i>faithful</i>, in the sense that no two inequivalent formulas construct the same graph (with labelling). Cographs are precisely the <i>\(N\)-free</i> grphs, where graph is called <i>\(N\)-free</i> when no induced subgraph on four vertices has exactly three edges.
			</p>

			<p>
				A slightly different graphical representation is used in [4] for the multiplicative fragment of intuitionistic propositional logic, where a combinatorial proof theory is also developed. In a talk I attended last year, given by Willem Heijltes and about [4], he mentioned that characterizing the graphs representing their formulas was a huge pain. While the ultimate aim of combinatorial proof theory is to...well...give a combinatorial account of proof theory, I think the faithful representation of formulas and the characterization of their graphs is itself an interesting and meaningful problem. At the very least, I hope that the project allows our friends in the combinatorial proof theory department to suffer just a little less.
			</p>

			<p>
				This project is mostly for-fun, so it isn't worked on actively all the time. I encourage anyone interested to get in contact and contribute. More information on the combinatorial proofs program can be found <a href="http://boole.stanford.edu/~dominic/proofs-without-syntax/">here</a>.
			</p>

			<h4>References</h4>
			<ol type="1">
				<li>Hughes, Dominic. “Proofs Without Syntax.” Annals of Mathematics 164.3 (2006): 1065–1076.</li>
				<li>Hughes, Dominic JD. "First-order proofs without syntax." arXiv preprint arXiv:1906.11236 (2019).</li>
				<li>Acclavio, Matteo, and Lutz Straßburger. "On Combinatorial proofs for modal logic." International Conference on Automated Reasoning with Analytic Tableaux and Related Methods. Springer, Cham, 2019.</li>
				<li>Heijltjes, Willem B., Dominic JD Hughes, and Lutz StraBburger. "Intuitionistic proofs without syntax." 2019 34th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS). IEEE, 2019.</li>
			</ol>
		</div>
	</div>
</body>


</html>
