<h1>Solving Polynomial Systems</h1>

<p>
    Last time, we saw that a couple of very simple languages... balancing parentheses, same amounts of \(a\)s as \(b\), etc... are nonregular! 
    By Kleene's Theorem, this amounts to the statement that there is no state in any finite automaton that accepts them (how rude!).
    The general slogan you hear people say about these languages is that they "require memory to recognize".
    This is true (and in a precise sense), but I think it is much easier to understand these languages from a systems-of-equations perspective.
    So that's what we are going to do today.
</p>
<p>
    We have already seen one way of generalizing our left-affine systems of equations: by allowing them to be unguarded (for there to be terms \(r_{ij}x_i\) where \(r_{ij}\) <i>does</i> have the empty word property). 
    Because of the Killing \(\varepsilon\)s with a Dagger construction, we can always transform one of these unguarded systems into a guarded one, so this generalization didn't buy us a larger family of languages than \(\mathsf{Rel}\).
    Today we are going to generalize even more: we're going to let go of "left-affine" and replace it with "polynomial". 
    This will lead us to a much bigger family of languages, including some languages you will be <i>very</i> familiar with.
</p>

<div class="example">
    <b>(A = B: Resurrection)</b>
    Let's start with a simple example and return to the language 
    \[
        L_{a = b} = \{a^n b^n \mid n \in \mathbb N\}
    \]
    from before.
    We already saw in the previous lecture that \(L \notin \mathsf{Reg}\) (we used the Pumping Lemma for this). 
    But it can still be written as a least solution to a system of equations. 
    In fact, it is the least solution to a single equation: 
    \[
        x = \varepsilon + a\cdot x\cdot b
    \]
    Let's see how this works.

    <p>
        Remember that a <i>solution</i> to this equation is a language \(L \subseteq A^*\) such that 
        \[
            L = \{\varepsilon\} \cup (\{a\} \cdot L \cdot \{b\})
        \]
        and that the <i>least</i> solution is the solution that is contained in all other solutions. 
        The language \(L_{a = b}\) satisfies this equation: \(\varepsilon \in L_{a = b}\) (set \(n = 0\)) and for any \(n \in \mathbb N\), \(a(a^nb^n)b = a^{n+1}b^{n+1} \in L_{a=b}\).
    </p>
    <p>
        To see that \(L_{a = b}\) is the <i>least</i> solution, we need to check that it <i>only contains the words it has to</i>. 
        To that end, let's consider an arbitrary solution \(L\).
        We know that \(\varepsilon \in L\), because the right-hand side explicitly requires \(\varepsilon \in L\). 
        Now, since \(\varepsilon \in L\), the second term on the right-hand side tells us that 
        \[
            a \varepsilon b = ab \in L
        \]
        Again, since \(ab \in L\), the equation also tells us that 
        \[
            a(ab)b = a^2b^2 \in L
        \]
        Continuing to plug words in \(L\) back into \(a \cdot (-) \cdot b\), it's not too hard to see that \(L_{a = b} \subseteq L\).
        This tells us that \(L_{a = b}\) is the smallest language that satisfies this equation!
    </p>
</div>

<p>
    In the example above, we just argued something very important: going from "left-affine" to "polynomial" <i>does</i> buy us more languages!
    That is, there are polynomial systems of equations whose least solutions are <i>not</i> regular. 
</p>

<div class="individual-exercise">
    <b>(A = B: Resurrection: Resurrection)</b>
    Rephrase the reasoning in the example above so that it is an explicit proof by induction of the inclusion \(L_{a = b} \subseteq L\) for any solution \(L\) to \(x = \varepsilon + axb\).
</div>

<div class="definition">
    <b>(Polynomial Expressions)</b>
    Let \(A\) be an alphabet of input letters, and let \(X = \{x_1, \cdots, x_n\}\) be a set of <i>variables</i> (which you can think of as taking languages as values).
    A <i>polynomial expression (over \(A\)) in \(X\) variables</i> is an expression formed from the following formation rules:
    <ol>
        <li>\(\emptyset\), \(\varepsilon\), and \(a\) are polynomials for any \(a \in A\)</li>
        <li>\(x\) is a polynomial expression for every \(x \in X\)</li>
        <li>If \(p_1(x_1, \dots, x_n), p_2(x_1, \dots, x_n)\) are polynomial expressions, then so are 
            <ol type="i">
                <li>\(p_1(x_1, \dots, x_n) + p_2(x_1, \dots, x_n)\)</li>
                <li>\(p_1(x_1, \dots, x_n) \cdot p_2(x_1, \dots, x_n)\)</li>
            </ol>
        </li>
    </ol>
    Above, we write \(p(x_1, \dots, x_n)\) to emphasize that the variables in the polynomial expression that appear are \(x_1, \dots, x_n \in X\). 

    <p>
        A <i>polynomial system of equations in \(X\) variables</i> is a system of equations of the form 
        \[\begin{aligned}
            x_1 &= p_1(x_1, \dots, x_n) \\
            &\ \vdots \\
            x_n &= p_n(x_1, \dots, x_n)
        \end{aligned}\]
        where \(x_1, \dots, x_n \in X\). 
        A <i>solution</i> to the polynomial system of equations in \(X\) variables above is a sequence of languages \(L_1, \dots, L_n\) such that 
        \[\begin{aligned}
            L_1 &= p_1(L_1, \dots, L_n) \\
            &\ \vdots \\
            L_n &= p_n(L_1, \dots, L_n)
        \end{aligned}\]
        That is, when you plug \(L_i\) into \(x_i\) for each \(x_i \in X\), then the equations between languages you obtain are true. 
        A <i>least solution</i> to the polynomial system of equations in \(X\) variables above is a solution \(U_1, \dots, U_n\) such that for any solution \(L_1, \dots, L_n\), \(U_i \subseteq L_i\) for all \(i = 1, \dots, n\).
    </p>
</div>

<p>
    The following individual exercise shows us that every regular language is the least solution to some polynomial system of equations.
</p>

<div class="individual-exercise">
    <b>(Left-Affine is Polynomial)</b>
    Show that every left-affine system of equations is a polynomial system of equations.
    Use Kleene's Theorem to explain why this means that every regular language is the least solution to some polynomial system of equations.
    <div class="hint">
        Set up the system of equations by using the formation rules for polynomial expressions to obtain left-affine equations.
    </div>
</div>

<div class="exercise">
    <b>(A=?)</b>
    Use the formation rules for polynomial expressions to write the polynomial 
    \[
        p(x) = (\varepsilon + a(x + b)x)b
        <!-- b + a(x + b)xb = b + axxb + abxb -->
    \]
    Now find \(5\) different words that appear in the least solution to the polynomial equation \(x = p(x)\) in \(\{x\}\) variables. 
    <div class="hint">
        Use Salomaa's axioms to simplify the polynomial up to language equivalence.
        What's the smallest word in the language?
    </div>
</div>

<div class="exercise">
    <b>(A=?)</b>
    Use the formation rules for polynomial expressions to write the polynomial 
    \[
        p(x) = \varepsilon + (a + b)x(a + b)
        <!-- \varepsilon + axa + axb + bxa + bxb -->
    \]
    Describe the least solution to the equation.
    <div class="hint">
        Use Salomaa's axioms to simplify the polynomial up to language equivalence.
        What's the smallest word in the language?
    </div>
</div>

<p>
    The thing about polynomial systems is that they're hard to solve.
    And unfortunately, Arden's Rules can't save us when it comes to finding these least solutions.
    We need to use a slightly different but more direct approach.
    This approach requires us to show that we can write polynomial expressions a certain way.
</p>

<div class="definition">
    <b>(Monomial)</b>
    Let \(A\) be an alphabet and \(X\) be a set of variables and assume that \(A \cap X = \{\}\) (there is no overlap between input letters and variables---this is an assumption we will always make).
    Then a <i>monomial expression</i> is a word \(\mu \in (X \cup A)^*\). 
    We write \(\mu(x_1, \dots, x_n)\) to emphasize that \(x_1, \dots, x_n\) are the variables that appear in \(\mu\).
</div>

<p>
    The set \((X \cup A)^*\) consists of all of the words you can form by expanding your alphabet to include \(X\).
    In other words, monomials are polynomials formed without using the \(+\) formation rule.
</p>

<div class="definition">
    <b>(Grammar Ready)</b>
    Given a polynomial expression \(p(x_1, \dots, x_n)\) over \(A\) in \(X\) variables, we say that <i>\(p\) is in grammar-ready form</i> if there are monomial expressions \(\mu_1, \dots, \mu_k \in (X \cup A)^*\) such that 
    \[
        p = \mu_1 + \mu_2 + \dots + \mu_k
    \]
    (Note that this is syntactic equality, not languguage equivalence.)
    A polynomial system of equations is <i>grammar-ready</i> if every polynomial expression that appears in it is in grammar-ready form.
</div>

<p>
    For example, all of
    \[
        axb
        \qquad 
        xxyabxybc + \varepsilon
        \qquad
        by + \varepsilon x y a
    \]
    are in grammar-ready form, but none of 
    \[
        ax(b + y)
        \qquad 
        xx(a + b)xybc + \varepsilon
        \qquad
        b(y + \varepsilon) x y a
    \]
    are not.
    However, every polynomial expression has a grammar-ready equivalent.
</p>

<div class="exercise">
    <b>(Getting Ready for School)</b>
    For each polynomial expression each of 
    \[
        p_1(x, y) = ax(b + y)
        \qquad 
        p_2(x, y) = xx(a + b)xybc + \varepsilon
        \qquad
        p_3(x, y) = b(y + \varepsilon) x y a
    \]
    find a language equivalent polynomial expression in grammar-ready form, i.e., \(q_i(x, y)\) that is in grammar-ready form and 
    \[
        p_i(x, y,) =_{\mathcal L} q_i(x, y)
    \]    
</div>

<p>
    As you can probably guess, the translation from non-grammar-ready to grammar-ready is always the same sequence of steps.
</p>

<div class="lemma">
    <b>(Grammar-Readiness)</b>
    Every polynomial system of equations has the same least solution as a grammar-ready polynomial system of equations.
</div>

<!--Section-->
<h2>Grammars</h2>

<p>
    Finding the least solution to a polynomial system of equations is always a matter of determining which words <i>have to be in any solution</i>.
    This is always a matter of plugging in words we have already determined are in the language into the right-hand side of the equation. 
    There is a more systematic way of writing this process down: it's called a <i>rewrite rule</i>.
    A set of reqwrite rules is called a <i>grammar</i>, although we will only consider one type of grammar for now. 
</p>

<div class="definition">
    <b>(Rewriting, Grammar)</b>
    Given a 
</div>