<h1>Kleene's Theorem</h1>

<p>
    We have already seen that \(\mathsf{Reg} \subseteq \mathsf{Fin}\).
    The proof of this inclusion entailed turning a regular expression \(r\) into a state of an automaton \(\mathcal A_{Ant}\) such that \(\mathcal L(\mathcal A_{Ant}, r) = \mathcal L(r)\).
    Today we're going to do the opposite: we are going to use a procedure (called <i>Kleene's algeorithm</i>) for turning a state in a finite automaton into a regular expression whose language semantics is the language accepted by the state.
    This procedure requires a bit of the algebra of regular expressions, which we explored last time, to solve certain systems of equations.
</p>

<p>
    To get at the "systems of equations" part, let's do a little analysis of a couple automata.
</p>

<div class="example">
    <b>(Finding a Regular Expression)</b>
    Consider the automata in the figure below.

    <div class="figure">
        <img src="../imgs/about-to-union.svg" alt="two automata" />
        Two two-state automata, \(\mathcal A_1\) and \(\mathcal A_2\).
    </div>

    <p>
        The one on the left, \(\mathcal A_1\), has two states: \(x_1\) and \(x_2\).
        We are going to calculate the language that \(x_1\) accepts.
        Whatever it is, call it \(L_1 = \mathcal L(\mathcal A_1, x_1)\), we know that any word of the form \(aw \in L_1\) has to have its \(w\) component accepted by \(x_2\), and conversely every word \(w\) accepted by \(x_2\) determines a word \(aw\ in L_1\).
        This ties the two languages together: let \(L_2 = \mathcal L(\mathcal A_2, x_2)\) be the language \(x_2\) accepts. 
        Then what we have deduced is that \(\{a\} \cdot L_2 \subseteq L_1\).
    </p>

    <p>
        Now, we also know that if \(w \in L_1\), then because \(x_1 \xrightarrow{b} x_1\), \(\{b\}\cdot L_1 \subseteq L_1\).
        But there are no other words in \(L_1\)! so we have arrived at the following equation:
        \[
            L_1 = (\{a\} \cdot L_2) \cup (\{b\} \cdot L_1)
        \]
        In terms of regular expressions, if \(s_1\) is a regular expression for \(L_1\) and \(s_2\) is a regular expression for \(L_2\), then the quation reads 
        \[
            s_1 =_{\mathcal L} as_2 + bs_1
        \]
        Now, check it out! 
        Since \(b\) does not have the empty word property, we can use Arden's rule to simplify this equation:
        \[\begin{aligned}
            \overbrace{\framebox{\(s_1\)}}^s 
            &=_{\mathcal L} \overbrace{(as_2)}^t + \overbrace{(b)}^r  \overbrace{\framebox{\(s_1\)}}^s \\
            &=_{\mathcal L} \overbrace{b^*}^{r^*}\overbrace{(a s_2)}^t && \text{(Arden's Rule)}
        \end{aligned}\]
        So it remains to figure out what \(s_2\) is.
    </p>

    <p>
        The situation for \(s_2\) is slightly different. 
        It's true that \(\{a\} \cdot L_1 \subseteq L_2\), and similarly that \(\{a\} \cdot L_2 \subseteq L_2\) and \(\{b\} \cdot L_2 \subseteq L_2\).
        But this isn't quite all of \(L_2\): we also know that \(\varepsilon \in L_2\).
        Altogether, that makes 
        \[
            L_2 = (\{\varepsilon\}) \cup (\{a\}\cdot L_1) \cup (\{a\}\cdot L_2) \cup (\{b\} \cdot L_2)
        \]
        In terms of regular expressions, this gives the equation
        \[
            s_2 =_{\mathcal L} \varepsilon + as_1 + as_2 + bs_2
        \]
        Collecting like terms (remember the Sequential Composition equations from the Algebra of Regular Expressions), we get 
        \[
            s_2 =_{\mathcal L} \varepsilon + as_1 + (a + b)s_2
        \]
        Now, \(a+b\) does not have the empty word property, so we get the following instance of Arden's rule:
        \[\begin{aligned}
            \overbrace{\framebox{\(s_2\)}}^s
            &=_{\mathcal L} \overbrace{(\varepsilon + as_1)}^t + \overbrace{(a + b)}^r \overbrace{\framebox{\(s_2\)}}^s \\
            &=_{\mathcal L} \overbrace{(a + b)^*}^{r^*}\overbrace{(\varepsilon + as_1)}^t && \text{(Arden's Rule)}
        \end{aligned}\]
        Note that the \(s_2\) disappears on the right-hand side, leaving \(s_1\) as an indeterminate variable.
    </p>

    <p>
        Now let's plug \(s_2\) back into the first equation. 
        This gives
        \[\begin{align}
            s_1 
            &= b^*(a((a + b)^*(\varepsilon + as_1))) && \text{substitute \(s_2\)} \\
            &= b^*(a(a + b)^*\varepsilon + a(a + b)^*as_1) && \text{distribute sequential composition} \\
            &= b^*a(a + b)^*\varepsilon + b^*a(a + b)^*as_1 && \text{distribute sequential composition} \\
            &= b^*a(a + b)^* + b^*a(a + b)^*as_1 && \text{\(\varepsilon\) sequential composition} \\
        \end{align}\]
        Again, \(b^*a(a + b)^*a\) does not have the empty word property (its language semantics contains words with two \(a\)s), so we have another instance of Arden's rule:
        \[\begin{aligned}
            \overbrace{\framebox{\(s_1\)}}^s 
            &= \overbrace{(b^*a(a + b)^*)}^t + \overbrace{(b^*a(a + b)^*a)}^r \overbrace{\framebox{\(s_1\)}}^s \\
            &= \overbrace{(b^*a(a + b)^*a)^*}^{r^*}\overbrace{(b^*a(a + b)^*)}^t && \text{\(\varepsilon\) sequential composition} \\
        \end{aligned}\]
        Aha! And there are no more \(s_1\) and \(s_2\)s in that equation!
    </p>
    <p>
        Using algebraic reasoning, we have come to the following conclusion: that the language accepted by \(x_2\) is the semantics of the regular expression...
        \[
            \mathcal L(\mathcal A_1, x_1) = \mathcal L(s_2) = \mathcal L(
                (b^*a(a + b)^*a)^*(b^*a(a + b)^*)
            )
        \]
        ...it's not a pretty regular expression, but this is generally how the method of deriving these equations works.
    </p>
</div>

<div class="exercise">
    <b>(Kleene is Kinda Dirty)</b>
    Find a shorter regular expression \(r\) whose language semantics is the language accepted by \(x_1\) in \(\mathcal A_1\) from the example above, i.e., \(\mathcal L(\mathcal A_1, x_1) = \mathcal L(r)\).
</div>

<p>
    In the example above, we used Arden's rule a bunch to fish out a regular expression from a system of equations that we obtained from an automaton. 
    Altogehter, the <i>system of equations</i> in the example was (and I have moved terms around a little bit)
    \[\begin{aligned}
        s_1 &= bs_1 + as_2 \\
        s_2 &=_{\mathcal L} \varepsilon + as_1 + (a + b)s_2
    \end{aligned}\]
    and to find the regular expression that corresponds to \(s_1\) we needed to eliminate the indeterminate variables, \(s_1\) and \(s_2\), from the right-hand side of each equation.
</p>

<p>
    It turns out that every system of equations of this form has a solution.
</p>

<div class="definition">
    <b>(Left-Affine System)</b>
    A <i>left-affine system of equations</i> is a system of equations of the form 
    \[\begin{aligned}
        x_1 &= b_1 + r_{11} x_1 + r_{12} x_2 + \cdots + r_{1n} x_n \\
        x_2 &= b_2 + r_{21} x_1 + r_{22} x_2 + \cdots + r_{2n} x_n \\
        &\hspace{2em} \vdots \\
        x_n &= b_n + r_{n1} x_1 + r_{n2} x_2 + \cdots + r_{nn} x_n 
    \end{aligned}\]
    where \(b_i,r_{ij} \in \mathit{RExp}\) are regular expressions and none of the \(r_{ij}\) have the empty word property.
    The variables \(x_1, \dots, x_n\) are called the <i>indeterminate variables</i> of the system.

    <p>
        A <i>solution</i> to the left-affine system of equations above is a sequence of regular expressions \(s_1, s_2, \dots, s_n\) such that 
        \[\begin{aligned}
            s_1 &=_{\mathcal L} b_1 + r_{11} s_1 + r_{12} s_2 + \cdots + r_{1n} s_n \\
            s_2 &=_{\mathcal L} b_2 + r_{21} s_1 + r_{22} s_2 + \cdots + r_{2n} s_n \\
            &\hspace{2em} \vdots \\
            s_n &=_{\mathcal L} b_n + r_{n1} s_1 + r_{n2} s_2 + \cdots + r_{nn} s_n 
        \end{aligned}\]
    </p>
    
    <p>Let \(\mathcal A = (Q, A, \delta, F)\) be a finite automaton, and write 
    \(Q = \{x_1, x_2, \dots, x_n\}\).
    The <i>left-affine system from \(\mathcal A\)</i>, \(\mathcal S(\mathcal A)\), is given by 
    \[\begin{aligned}
        x_1 &= b_1 + r_{11} x_1 + r_{12} x_2 + \cdots + r_{1n} x_n \\
        x_2 &= b_2 + r_{21} x_1 + r_{22} x_2 + \cdots + r_{2n} x_n \\
        &\hspace{2em} \vdots \\
        x_n &= b_n + r_{n1} x_1 + r_{n2} x_2 + \cdots + r_{nn} x_n 
    \end{aligned}\]
    where 
    \[
        b_i = \begin{cases}
            \varepsilon &\text{if \(x_i \in F\)} \\
            \emptyset &\text{if \(x_i \notin F\)}
        \end{cases}
    \]
    and 
    \[
        r_{ij} = \sum_{(x_i, a, x_j) \in \delta} a
    \]
    </p>
</div>

<p>
    I slipped something under the rug in the definition above...
    You should take a moment to convince yourself that \(\mathcal S(\mathcal A)\) is always a left-affine system (pay attention to the empty word property part).
</p>

<div class="exercise">
    <b>(Solving One-variable Systems)</b>
    Set up the left-affine system of equations for each of the following automata and solve them using Arden's rule.
    <ol>
        <li>The all-accepting automaton, \(\mathcal A_\checkmark = (\{s_0\}, \{a, b\}, \{(s_0, a, s_0), (s_0, b, s_0)\}, \{s_0\})\)</li>
        <li>The sink automaton, \(\mathcal A_\bullet = (\{s_0\}, \{a, b\}, \{\}, \{\})\)</li>
        <li>The diverging loop, \(\mathcal A_\circlearrowright = (\{s_0\}, \{a, b\}, \{(s_0, a, s_0), (s_0, b, s_0)\}, \{\})\)</li>
        <li>The automaton that only accepts, \(\mathcal A_\varepsilon = (\{s_0\}, \{a, b\}, \{\}, \{s_0\})\)</li>
    </ol>
</div>

<p>
    The next theorem states that solving the left-affine system of equations for an automaton finds you all the regular expressions that correspond to its states.
    The reason is a kind of it-works-by-design type deal, as we saw in the Finding a Regular Expression Example.
</p>

<div class="theorem">
    <b>(Solutions are Solutions)</b>
    Let \(\mathcal A = (Q, A, \delta, F)\) be a finite automaton with \(Q = \{x_1, \dots, x_n\}\), and consider its left-affine system of equations \(\mathcal S(\mathcal A)\).
    If \(s_1,\dots, s_n \in \mathit{RExp}\) is a solution to \(\mathcal S(\mathcal A)\), then for each \(i = 1,\dots, n\), \(\mathcal L(\mathcal A, x_i) = \mathcal L(s_i)\).
</div>

<h2>Kleene's Algorithm and Kleene's Theorem</h2>

<p>
    It turns out that every left-affine system of equations has a (in fact, unique) solution.
    The most important part of this section is <i>Kleene's algorithm</i>, which finds that solution always.
</p>

<p>
    Kleene's algorithm is recursive, which means that it has a <i>base case</i> and a <i>recursive step</i>.
    Basically, you recurse on the number of indeterminate variables in the left-affine system:
    if the number of variables is zero, then you are done.
    There are no indeterminate variables, so all of the regular expressions on the right-hand side are explicit regular expressions with no \(x_i\)s in them. 
</p>

<p>
    In the recursive step, you will have a left-affine system of the form
    \[\begin{aligned}
        x_1 &= b_1 + r_{11} x_1 + r_{12} x_2 + \cdots + r_{1n} x_n + r_{1(n+1)}x_{n+1} \\
        x_2 &= b_2 + r_{21} x_1 + r_{22} x_2 + \cdots + r_{2n} x_n + r_{2(n+1)}x_{n+1} \\
        &\hspace{2em} \vdots \\
        x_n &= b_n + r_{n1} x_1 + r_{n2} x_2 + \cdots + r_{nn} x_n + r_{n(n+1)}x_{n+1} \\
        x_{n+1} &= b_{n+1} + r_{(n+1)1} x_1 + r_{(n+1)2} x_2 + \cdots + r_{(n+1)n} x_n + r_{(n+1)(n+1)}x_{n+1} 
    \end{aligned}\]
    The idea is to start as follows: observe that the \((n+1)\)th equation is an instance of Arden's rule, because \(r_{(n+1)(n+1)}\) does not have the empty word property.
    \[\begin{aligned}
        x_{n+1} 
        &= \overbrace{b_{n+1} + r_{(n+1)1} x_1 + \cdots + r_{(n+1)n} x_n}^t + \overbrace{r_{(n+1)(n+1)}}^r    \overbrace{x_{n+1}}^s \\
        &= \overbrace{(r_{(n+1)(n+1)})^*}^{r^*}\overbrace{(b_{n+1} + r_{(n+1)1} x_1 + \cdots + r_{(n+1)n} x_n)}^t  &&\text{(Arden's Rule)} \\
    \end{aligned}\]
    Now we can distribute the \((r_{(n+1)(n+1)})^*\) to get 
    \[
        x_{n+1} = (r_{(n+1)(n+1)})^* b_{n+1} + (r_{(n+1)(n+1)})^*r_{(n+1)1} x_1 + \cdots + (r_{(n+1)(n+1)})^*r_{(n+1)n} x_n 
    \]
    This has one fewer indeterminate variable!
    Now we can plug this back into the rest of the left-affine system to get a system of equations with only \(n\) indeterminate variables. 
    \[\begin{aligned}
        x_1 
            &= b_1 + r_{11} x_1 + \cdots + r_{1n} x_n \\
            & \hspace{3em} + r_{1(n+1)}((r_{(n+1)(n+1)})^* b_{n+1} + (r_{(n+1)(n+1)})^*r_{(n+1)1} x_1 + \cdots + (r_{(n+1)(n+1)})^*r_{(n+1)n} x_n) \\
        x_2 
            &= b_2 + r_{21} x_1 + \cdots + r_{2n} x_n \\
            & \hspace{3em} + r_{2(n+1)}((r_{(n+1)(n+1)})^* b_{n+1} + (r_{(n+1)(n+1)})^*r_{(n+1)1} x_1 + \cdots + (r_{(n+1)(n+1)})^*r_{(n+1)n} x_n) \\
        &\hspace{2em} \vdots \\
        x_n 
            &= b_n + r_{n1} x_1 + \cdots + r_{nn} x_n \\
            & \hspace{3em} + r_{n(n+1)}((r_{(n+1)(n+1)})^* b_{n+1} + (r_{(n+1)(n+1)})^*r_{(n+1)1} x_1 + \cdots + (r_{(n+1)(n+1)})^*r_{(n+1)n} x_n) \\
    \end{aligned}\]
    Using distributivity and collecting like terms turns the above system of equations into a left-affine system of equations.
    For example, we can turn the first equation into 
    \[\begin{aligned}
        x_1 
            &= (b_1 + r_{1(n+1)}(r_{(n+1)(n+1)})^* b_{n+1})
                + (r_{11} + r_{1(n+1)}(r_{(n+1)(n+1)})^*r_{(n+1)1}) x_1 \\
                &\hspace{3em} + \cdots 
                + (r_{1n} + r_{1(n+1)}(r_{(n+1)(n+1)})^*r_{(n+1)n}) x_n \\
    \end{aligned}\]
</p>

<p>
    Is it pretty? No, but it does work!
</p>

<div class="theorem">
    <b>(Systems have Solutions)</b>
    Every left-affine system of equations has a solution.
    Furthermore, Kleene's algorithm finds this solution.
</div>

<div class="example">
    <b>(Returning to Finding a Regular Expression)</b>
    Following the definition literally, the left-affine system \(\mathcal S(\mathcal A_2)\) corresponding to the second automaton in the Finding a Regular Expression example is 
    \[\begin{aligned}
        y_1 &= \emptyset + ay_1 + by_2 \\
        y_2 &= \varepsilon + (a + b)y_1 + \emptyset y_2
    \end{aligned}\]
    The first equation comes from \(b_1 = \emptyset\) (\(y_1\) is not accepting), \(y_1 \xrightarrow{a} y_2\), and \(y_1 \xrightarrow{b} y_2\) in the definition.
    The second equation comes from \(b_2 = \varepsilon\) (\(y_2\) is accepting), \(y_2 \xrightarrow{a,b} y_1\), and that there are no transitions \(y_2 \to y_2\).

    <p>
        Kleene's algorithm tells us that we need to deal with the last equation first. 
        Since \(\mathcal L(\emptyset)\) does not have the empty word property, we use Arden's rule to eliminate the \(y_2\) on the right-hand side. 
        We get the following calculation out of this, where I've included some simplifying (using the Using the Basic Equations exercise from earlier).
        \[\begin{aligned}
            y_2 
            &= \varepsilon + (a + b)y_1 + \emptyset y_2 \\
            &= \emptyset^*(\varepsilon + (a + b)y_1) &&\text{(Arden's Rule)} \\
            &= \varepsilon(\varepsilon + (a + b)y_1) &&\text{(Using the Basic Equations)} \\
            &= \varepsilon + (a + b)y_1 &&\text{(\(\varepsilon\) sequential composition)} 
        \end{aligned}\]
        Now Kleene's theorem tells us we want to plug this back into the first equation and collect like terms: 
        \[\begin{aligned}
            y_1 
            &= \emptyset + ay_1 + by_2 \\
            &= \emptyset + ay_1 + b(\varepsilon + (a + b)y_1) \\
            &= \emptyset + ay_1 + b\varepsilon + b(a + b)y_1 &&\text{distribute} \\
            &= \emptyset + ay_1 + b + b(a + b)y_1 &&\text{\(\varepsilon\) seq comp} \\
            &= \emptyset + b  + ay_1 + b(a + b)y_1 &&\text{union rules} \\
            &= (\emptyset + b) + (a + b(a + b))y_1 &&\text{collect like terms} \\
        \end{aligned}\]
        Kleene's algorithm now tells us to use Arden's rule to finish the calculation.
        \[\begin{aligned}
            y_1 
            &= (\emptyset + b) + (a + b(a + b))y_1  \\
            &= (a + b(a + b))^*(\emptyset + b) &&\text{Arden's Rule} \\
        \end{aligned}\]
        <!-- One nice thing about this example is that \(y_2\) does not appear in the last equation.  -->
        This means that we proceed to the next step, which is to 

    </p>
</div>

<div class="exercise">
    <b>(Setting Things Up)</b>
    Write down the left-affine system of equations for automaton \(\mathcal A_2\) in the Finding a Regular Expression example.
    Find a solution to the system using the same kind of reasoning as in the example.
</div>

<p>
    Because it guarantees a solution always, Kleene's algorithm is a good one to practice a couple times.
    It's not hard to understand that it works, I think, but using it can be a bit tricky.
</p>

<p>
    The significance of Kleene's algorithm, left-affine systems and their solutions, and Antimirov derivatives, is that together they land us at the following theorem.
</p>

<div class="theorem">
    <b>(Kleene's Theorem)</b>
    Let \(L \subseteq A^*\) be a language. 
    Then \(L\) is accepted by a state in a finite automaton if and only if \(L\) is the language semantics of somer egular expression. 
    Formally,
    \[\mathsf{Fin} = \mathsf{Reg}\]
</div>

<div class="exercise">
    <b>(Kleening Up)</b>
    In each automaton, find the 
</div>

<div class="problem">
    <b>(Some String Matching)</b>
    Let \(A = \{0,1\}\).
    In the following automaton, the state \(x_0\) represents a program that checks that in a given input string, every instance of \(01\) is <i>eventually</i> followed by a \(0\).
    <div class="figure">
        <img src="../imgs/01then0.svg" alt="an automaton with a state that accepts every string where 01 is eventually followed by 0"/>
        An automaton \(\mathcal A\) with a state \(x_0\) that accepts a string of \(0\)s and \(1\)s if and only if every instance of \(01\) is eventually followed by \(0\).
    </div>
    <ol>
        <li>Use Kleene's algorithm to derive a regular expression \(s_0 \in \mathit{RExp}\) such that \(\mathcal L(\mathcal A, x_0) = \mathcal L(s_0)\).</li>
        <li>
            Draw the portion of the Antimirov automaton generated by \(s_0\), \(\mathcal A' = \langle s_0\rangle_{\mathcal A_{Ant}}\). 
            There is a state \(y_0\) is the Antimirov automaton such that \(\mathcal A = \langle y_0\rangle_{\mathcal A'}\).
            Find \(y_0\).
        </li>
    </ol>
</div>